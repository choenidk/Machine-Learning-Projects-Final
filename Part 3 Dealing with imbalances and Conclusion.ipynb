{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>3.2) Dealing with imbalance</h1></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we saw in the second section of the project I still have problems with correctly classifying the two smallest classes so I will use two sampling techniques to address the imbalance in the dataset. The two approaches have the same goal but act on opposite sides. While oversampling modifies the two minority classes undersampling modifies the biggest class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Oversampling</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the SMOTE algorithm to augment the two smallest classes (non fundet and partially funded loans). SMOTE stands for Synthetic Minority Over-sampling Technique.\n",
    "\n",
    "The idea behind the algorithm is to create synthetic data points that are similar to existing data points that share the same characteristics.. By using smote I will increase the size of the two smallest classes so they match the biggest class in size and will therefore remove class imbalance.\n",
    "\n",
    "Smote is unfortunately not part of Sklearn or Keras and the package has to be installed separately. It can be installed from this site: https://pypi.org/project/imbalanced-learn/\n",
    "\n",
    "The biggest drawback with smote is computing time as the dataset gets, in this case, multiplied by three.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335581, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the prepared file from\n",
    "kiva_smote = pd.read_csv('data_files/kiva_keras.csv')\n",
    "#reduce dataset with half ao the augmented dataset doesn't get to big\n",
    "kiva_undersampling = kiva_smote\n",
    "kiva_smote = kiva_smote.sample(frac=0.5,random_state=1)\n",
    "kiva_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>description</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>activity</th>\n",
       "      <th>sector</th>\n",
       "      <th>country</th>\n",
       "      <th>currency</th>\n",
       "      <th>term_in_months</th>\n",
       "      <th>lender_count</th>\n",
       "      <th>borrower_genders</th>\n",
       "      <th>repayment_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63804</th>\n",
       "      <td>1050.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Totally funded</td>\n",
       "      <td>Pigs</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>IDR</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33</td>\n",
       "      <td>Female</td>\n",
       "      <td>irregular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510864</th>\n",
       "      <td>400.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Totally funded</td>\n",
       "      <td>Embroidery</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>PKR</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595924</th>\n",
       "      <td>300.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Totally funded</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>Food</td>\n",
       "      <td>El Salvador</td>\n",
       "      <td>USD</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Male</td>\n",
       "      <td>monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580780</th>\n",
       "      <td>500.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Totally funded</td>\n",
       "      <td>Sewing</td>\n",
       "      <td>Services</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>PKR</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Female</td>\n",
       "      <td>irregular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344839</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Totally funded</td>\n",
       "      <td>Farming</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>KHR</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>monthly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loan_amount description     loan_status    activity       sector  \\\n",
       "63804        1050.0         Yes  Totally funded        Pigs  Agriculture   \n",
       "510864        400.0         Yes  Totally funded  Embroidery         Arts   \n",
       "595924        300.0         Yes  Totally funded      Bakery         Food   \n",
       "580780        500.0         Yes  Totally funded      Sewing     Services   \n",
       "344839       1200.0         Yes  Totally funded     Farming  Agriculture   \n",
       "\n",
       "            country currency  term_in_months  lender_count borrower_genders  \\\n",
       "63804     Indonesia      IDR             8.0            33           Female   \n",
       "510864     Pakistan      PKR            14.0            15           Female   \n",
       "595924  El Salvador      USD             8.0             7             Male   \n",
       "580780     Pakistan      PKR            11.0            14           Female   \n",
       "344839     Cambodia      KHR            13.0            26           Female   \n",
       "\n",
       "       repayment_interval  \n",
       "63804           irregular  \n",
       "510864            monthly  \n",
       "595924            monthly  \n",
       "580780          irregular  \n",
       "344839            monthly  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva_smote.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preproccesing keras\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "#features_to_scale = ['loan_amount','term_in_months','lender_count']\n",
    "scaler = MinMaxScaler()\n",
    "#scaled_features = scaler.fit_transform(kiva[features_to_scale])\n",
    "\n",
    "kiva_smote = pd.get_dummies(data=kiva_smote, columns=['activity','description', 'sector', 'country','currency','repayment_interval','borrower_genders'])\n",
    "kiva_smote[['loan_amount','term_in_months','lender_count']] = scaler.fit_transform(kiva_smote[['loan_amount','term_in_months','lender_count']])\n",
    "\n",
    "#kiva_keras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove funded amount and separate th Y form the X\n",
    "y = kiva_smote.loan_status\n",
    "kiva_smote.drop(['loan_status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply smotefrom imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(kiva_smote, y, test_size=0.2, random_state=0, shuffle=True)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Encode train_y\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_step_one = le.fit_transform(y_res)\n",
    "smote_train_y = to_categorical(y_train_step_one)\n",
    "# Encode train_y\n",
    "\n",
    "y_test_step_one = le.fit_transform(y_test)\n",
    "keras_test_y = to_categorical(y_test_step_one)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Caveat:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I haven’t changed the architecture of the model or the parameters. In this part of the project I wanted to see if balancing the classes led to improvements in the metrics. \n",
    "\n",
    "This is not the best approach. The GridsearchCV used in part two was based on the original, imbalanced dataset. We can’t say that the optimal parameters for the first dataset are optimal for the augmented set. Unfortunately running Gridsearch or Randomsearch on nearly two million samples would take probably days. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 598312 samples, validate on 149579 samples\n",
      "Epoch 1/80\n",
      "598312/598312 [==============================] - 90s 150us/step - loss: 0.6631 - acc: 0.7110 - val_loss: 1.2459 - val_acc: 0.3377\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.24587, saving model to weights.bestsmote.hdf5\n",
      "Epoch 2/80\n",
      "598312/598312 [==============================] - 89s 148us/step - loss: 0.5074 - acc: 0.7926 - val_loss: 1.0644 - val_acc: 0.4742\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.24587 to 1.06441, saving model to weights.bestsmote.hdf5\n",
      "Epoch 3/80\n",
      "598312/598312 [==============================] - 92s 154us/step - loss: 0.4083 - acc: 0.8408 - val_loss: 1.0882 - val_acc: 0.4772\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.06441\n",
      "Epoch 4/80\n",
      "598312/598312 [==============================] - 90s 150us/step - loss: 0.3419 - acc: 0.8709 - val_loss: 0.8822 - val_acc: 0.5575\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.06441 to 0.88222, saving model to weights.bestsmote.hdf5\n",
      "Epoch 5/80\n",
      "598312/598312 [==============================] - 94s 156us/step - loss: 0.2982 - acc: 0.8887 - val_loss: 0.8710 - val_acc: 0.6635\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.88222 to 0.87099, saving model to weights.bestsmote.hdf5\n",
      "Epoch 6/80\n",
      "598312/598312 [==============================] - 93s 156us/step - loss: 0.2691 - acc: 0.9002 - val_loss: 0.6142 - val_acc: 0.7040\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.87099 to 0.61425, saving model to weights.bestsmote.hdf5\n",
      "Epoch 7/80\n",
      "598312/598312 [==============================] - 93s 156us/step - loss: 0.2494 - acc: 0.9074 - val_loss: 0.6424 - val_acc: 0.7016\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.61425\n",
      "Epoch 8/80\n",
      "598312/598312 [==============================] - 90s 151us/step - loss: 0.2315 - acc: 0.9142 - val_loss: 0.5689 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.61425 to 0.56889, saving model to weights.bestsmote.hdf5\n",
      "Epoch 9/80\n",
      "598312/598312 [==============================] - 91s 152us/step - loss: 0.2207 - acc: 0.9182 - val_loss: 0.5054 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.56889 to 0.50542, saving model to weights.bestsmote.hdf5\n",
      "Epoch 10/80\n",
      "598312/598312 [==============================] - 90s 151us/step - loss: 0.2080 - acc: 0.9230 - val_loss: 0.5854 - val_acc: 0.7378\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.50542\n",
      "Epoch 11/80\n",
      "598312/598312 [==============================] - 92s 154us/step - loss: 0.1996 - acc: 0.9262 - val_loss: 0.5368 - val_acc: 0.7541\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.50542\n",
      "Epoch 12/80\n",
      "598312/598312 [==============================] - 91s 152us/step - loss: 0.1926 - acc: 0.9285 - val_loss: 0.5709 - val_acc: 0.7484\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.50542\n",
      "Epoch 13/80\n",
      "598312/598312 [==============================] - 93s 155us/step - loss: 0.1865 - acc: 0.9306 - val_loss: 0.4844 - val_acc: 0.7931\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.50542 to 0.48441, saving model to weights.bestsmote.hdf5\n",
      "Epoch 14/80\n",
      "598312/598312 [==============================] - 91s 153us/step - loss: 0.1816 - acc: 0.9319 - val_loss: 0.4896 - val_acc: 0.7885\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.48441\n",
      "Epoch 15/80\n",
      "598312/598312 [==============================] - 93s 156us/step - loss: 0.1767 - acc: 0.9337 - val_loss: 0.3637 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.48441 to 0.36369, saving model to weights.bestsmote.hdf5\n",
      "Epoch 16/80\n",
      "598312/598312 [==============================] - 94s 157us/step - loss: 0.1727 - acc: 0.9353 - val_loss: 0.3742 - val_acc: 0.8414\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.36369\n",
      "Epoch 17/80\n",
      "598312/598312 [==============================] - 93s 155us/step - loss: 0.1692 - acc: 0.9364 - val_loss: 0.5850 - val_acc: 0.7530\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.36369\n",
      "Epoch 18/80\n",
      "598312/598312 [==============================] - 93s 155us/step - loss: 0.1649 - acc: 0.9379 - val_loss: 0.5755 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.36369\n",
      "Epoch 19/80\n",
      "598312/598312 [==============================] - 93s 155us/step - loss: 0.1620 - acc: 0.9388 - val_loss: 0.3209 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.36369 to 0.32089, saving model to weights.bestsmote.hdf5\n",
      "Epoch 20/80\n",
      "598312/598312 [==============================] - 95s 159us/step - loss: 0.1587 - acc: 0.9398 - val_loss: 0.5186 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.32089\n",
      "Epoch 21/80\n",
      "598312/598312 [==============================] - 93s 155us/step - loss: 0.1573 - acc: 0.9401 - val_loss: 0.2939 - val_acc: 0.8891\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.32089 to 0.29394, saving model to weights.bestsmote.hdf5\n",
      "Epoch 22/80\n",
      "598312/598312 [==============================] - 95s 159us/step - loss: 0.1541 - acc: 0.9415 - val_loss: 0.2739 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.29394 to 0.27385, saving model to weights.bestsmote.hdf5\n",
      "Epoch 23/80\n",
      "598312/598312 [==============================] - 96s 160us/step - loss: 0.1528 - acc: 0.9420 - val_loss: 0.4180 - val_acc: 0.8257\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.27385\n",
      "Epoch 24/80\n",
      "598312/598312 [==============================] - 95s 160us/step - loss: 0.1494 - acc: 0.9427 - val_loss: 0.5614 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.27385\n",
      "Epoch 25/80\n",
      "598312/598312 [==============================] - 96s 160us/step - loss: 0.1477 - acc: 0.9433 - val_loss: 0.3544 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.27385\n",
      "Epoch 26/80\n",
      "598312/598312 [==============================] - 96s 161us/step - loss: 0.1464 - acc: 0.9437 - val_loss: 0.4601 - val_acc: 0.8038\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.27385\n",
      "Epoch 27/80\n",
      "598312/598312 [==============================] - 94s 158us/step - loss: 0.1441 - acc: 0.9447 - val_loss: 0.5411 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.27385\n",
      "Epoch 28/80\n",
      "598312/598312 [==============================] - 94s 157us/step - loss: 0.1429 - acc: 0.9451 - val_loss: 0.4327 - val_acc: 0.8215\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.27385\n",
      "Epoch 29/80\n",
      "598312/598312 [==============================] - 95s 158us/step - loss: 0.1418 - acc: 0.9452 - val_loss: 0.3383 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.27385\n",
      "Epoch 30/80\n",
      "598312/598312 [==============================] - 95s 158us/step - loss: 0.1402 - acc: 0.9461 - val_loss: 0.2855 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.27385\n",
      "Epoch 31/80\n",
      "598312/598312 [==============================] - 95s 159us/step - loss: 0.1391 - acc: 0.9465 - val_loss: 0.4300 - val_acc: 0.8225\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.27385\n",
      "Epoch 32/80\n",
      "598312/598312 [==============================] - 96s 160us/step - loss: 0.1375 - acc: 0.9470 - val_loss: 0.4579 - val_acc: 0.7985\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.27385\n",
      "Epoch 33/80\n",
      "598312/598312 [==============================] - 96s 160us/step - loss: 0.1370 - acc: 0.9473 - val_loss: 0.2877 - val_acc: 0.8877\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.27385\n",
      "Epoch 34/80\n",
      "598312/598312 [==============================] - 97s 162us/step - loss: 0.1350 - acc: 0.9475 - val_loss: 0.4444 - val_acc: 0.8149\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.27385\n",
      "Epoch 35/80\n",
      "598312/598312 [==============================] - 96s 161us/step - loss: 0.1342 - acc: 0.9482 - val_loss: 0.4153 - val_acc: 0.8301\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.27385\n",
      "Epoch 36/80\n",
      "598312/598312 [==============================] - 98s 164us/step - loss: 0.1336 - acc: 0.9485 - val_loss: 0.3372 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.27385\n",
      "Epoch 37/80\n",
      "598312/598312 [==============================] - 97s 161us/step - loss: 0.1320 - acc: 0.9488 - val_loss: 0.4281 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.27385\n",
      "Epoch 38/80\n",
      "598312/598312 [==============================] - 97s 162us/step - loss: 0.1304 - acc: 0.9497 - val_loss: 0.3124 - val_acc: 0.8699\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.27385\n",
      "Epoch 39/80\n",
      "598312/598312 [==============================] - 98s 164us/step - loss: 0.1300 - acc: 0.9497 - val_loss: 0.4223 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.27385\n",
      "Epoch 40/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598312/598312 [==============================] - 90s 150us/step - loss: 0.1286 - acc: 0.9505 - val_loss: 0.3313 - val_acc: 0.8597\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.27385\n",
      "Epoch 41/80\n",
      "598312/598312 [==============================] - 88s 147us/step - loss: 0.1277 - acc: 0.9507 - val_loss: 0.3132 - val_acc: 0.8776\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.27385\n",
      "Epoch 42/80\n",
      "598312/598312 [==============================] - 88s 148us/step - loss: 0.1269 - acc: 0.9512 - val_loss: 0.4280 - val_acc: 0.8257\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.27385\n",
      "Epoch 43/80\n",
      "598312/598312 [==============================] - 90s 150us/step - loss: 0.1253 - acc: 0.9517 - val_loss: 0.3346 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.27385\n",
      "Epoch 44/80\n",
      "598312/598312 [==============================] - 89s 149us/step - loss: 0.1250 - acc: 0.9519 - val_loss: 0.3415 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.27385\n",
      "Epoch 45/80\n",
      "598312/598312 [==============================] - 89s 149us/step - loss: 0.1232 - acc: 0.9523 - val_loss: 0.5011 - val_acc: 0.7931\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.27385\n",
      "Epoch 46/80\n",
      "598312/598312 [==============================] - 89s 149us/step - loss: 0.1226 - acc: 0.9523 - val_loss: 0.3121 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.27385\n",
      "Epoch 47/80\n",
      "598312/598312 [==============================] - 90s 150us/step - loss: 0.1220 - acc: 0.9528 - val_loss: 0.4325 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.27385\n",
      "Epoch 48/80\n",
      "598312/598312 [==============================] - 89s 149us/step - loss: 0.1210 - acc: 0.9530 - val_loss: 0.5236 - val_acc: 0.7955\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.27385\n",
      "Epoch 49/80\n",
      "598312/598312 [==============================] - 90s 150us/step - loss: 0.1202 - acc: 0.9532 - val_loss: 0.2878 - val_acc: 0.8895\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.27385\n",
      "Epoch 50/80\n",
      "598312/598312 [==============================] - 90s 150us/step - loss: 0.1191 - acc: 0.9539 - val_loss: 0.2687 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.27385 to 0.26870, saving model to weights.bestsmote.hdf5\n",
      "Epoch 51/80\n",
      "598312/598312 [==============================] - 91s 151us/step - loss: 0.1189 - acc: 0.9539 - val_loss: 0.3208 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.26870\n",
      "Epoch 52/80\n",
      "598312/598312 [==============================] - 89s 149us/step - loss: 0.1184 - acc: 0.9541 - val_loss: 0.2565 - val_acc: 0.8996\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.26870 to 0.25653, saving model to weights.bestsmote.hdf5\n",
      "Epoch 53/80\n",
      "598312/598312 [==============================] - 91s 152us/step - loss: 0.1180 - acc: 0.9544 - val_loss: 0.3023 - val_acc: 0.8817\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.25653\n",
      "Epoch 54/80\n",
      "598312/598312 [==============================] - 91s 152us/step - loss: 0.1166 - acc: 0.9546 - val_loss: 0.3518 - val_acc: 0.8597\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.25653\n",
      "Epoch 55/80\n",
      "598312/598312 [==============================] - 92s 154us/step - loss: 0.1157 - acc: 0.9550 - val_loss: 0.2605 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.25653\n",
      "Epoch 56/80\n",
      "598312/598312 [==============================] - 90s 151us/step - loss: 0.1148 - acc: 0.9553 - val_loss: 0.3580 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.25653\n",
      "Epoch 57/80\n",
      "598312/598312 [==============================] - 90s 151us/step - loss: 0.1144 - acc: 0.9554 - val_loss: 0.2174 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.25653 to 0.21740, saving model to weights.bestsmote.hdf5\n",
      "Epoch 58/80\n",
      "598312/598312 [==============================] - 91s 153us/step - loss: 0.1142 - acc: 0.9555 - val_loss: 0.3587 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.21740\n",
      "Epoch 59/80\n",
      "598312/598312 [==============================] - 92s 154us/step - loss: 0.1136 - acc: 0.9558 - val_loss: 0.3193 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.21740\n",
      "Epoch 60/80\n",
      "598312/598312 [==============================] - 92s 154us/step - loss: 0.1133 - acc: 0.9557 - val_loss: 0.4634 - val_acc: 0.8261\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.21740\n",
      "Epoch 61/80\n",
      "598312/598312 [==============================] - 92s 153us/step - loss: 0.1124 - acc: 0.9565 - val_loss: 0.2507 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.21740\n",
      "Epoch 62/80\n",
      "598312/598312 [==============================] - 97s 162us/step - loss: 0.1125 - acc: 0.9563 - val_loss: 0.3779 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.21740\n",
      "Epoch 63/80\n",
      "598312/598312 [==============================] - 95s 158us/step - loss: 0.1118 - acc: 0.9560 - val_loss: 0.3113 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.21740\n",
      "Epoch 64/80\n",
      "598312/598312 [==============================] - 93s 155us/step - loss: 0.1112 - acc: 0.9565 - val_loss: 0.1850 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.21740 to 0.18498, saving model to weights.bestsmote.hdf5\n",
      "Epoch 65/80\n",
      "598312/598312 [==============================] - 92s 155us/step - loss: 0.1105 - acc: 0.9567 - val_loss: 0.4726 - val_acc: 0.8124\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.18498\n",
      "Epoch 66/80\n",
      "598312/598312 [==============================] - 93s 155us/step - loss: 0.1110 - acc: 0.9566 - val_loss: 0.2485 - val_acc: 0.9063\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.18498\n",
      "Epoch 67/80\n",
      "598312/598312 [==============================] - 92s 154us/step - loss: 0.1105 - acc: 0.9569 - val_loss: 0.3512 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.18498\n",
      "Epoch 68/80\n",
      "598312/598312 [==============================] - 93s 155us/step - loss: 0.1102 - acc: 0.9568 - val_loss: 0.2213 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.18498\n",
      "Epoch 69/80\n",
      "598312/598312 [==============================] - 93s 155us/step - loss: 0.1098 - acc: 0.9568 - val_loss: 0.2339 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.18498\n",
      "Epoch 70/80\n",
      "598312/598312 [==============================] - 93s 155us/step - loss: 0.1092 - acc: 0.9571 - val_loss: 0.2555 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.18498\n",
      "Epoch 71/80\n",
      "598312/598312 [==============================] - 92s 155us/step - loss: 0.1087 - acc: 0.9574 - val_loss: 0.2918 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.18498\n",
      "Epoch 72/80\n",
      "598312/598312 [==============================] - 92s 154us/step - loss: 0.1087 - acc: 0.9574 - val_loss: 0.3438 - val_acc: 0.8820\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.18498\n",
      "Epoch 73/80\n",
      "598312/598312 [==============================] - 94s 158us/step - loss: 0.1082 - acc: 0.9575 - val_loss: 0.3326 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.18498\n",
      "Epoch 74/80\n",
      "598312/598312 [==============================] - 93s 156us/step - loss: 0.1083 - acc: 0.9575 - val_loss: 0.4028 - val_acc: 0.8365\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.18498\n",
      "Epoch 75/80\n",
      "598312/598312 [==============================] - 94s 158us/step - loss: 0.1078 - acc: 0.9576 - val_loss: 0.3700 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.18498\n",
      "Epoch 76/80\n",
      "598312/598312 [==============================] - 94s 157us/step - loss: 0.1075 - acc: 0.9576 - val_loss: 0.2928 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.18498\n",
      "Epoch 77/80\n",
      "598312/598312 [==============================] - 94s 157us/step - loss: 0.1072 - acc: 0.9577 - val_loss: 0.5437 - val_acc: 0.7867\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.18498\n",
      "Epoch 78/80\n",
      "598312/598312 [==============================] - 93s 156us/step - loss: 0.1071 - acc: 0.9577 - val_loss: 0.3326 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.18498\n",
      "Epoch 79/80\n",
      "598312/598312 [==============================] - 93s 156us/step - loss: 0.1069 - acc: 0.9578 - val_loss: 0.2482 - val_acc: 0.9058\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.18498\n",
      "Epoch 80/80\n",
      "598312/598312 [==============================] - 96s 160us/step - loss: 0.1064 - acc: 0.9580 - val_loss: 0.2246 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.18498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x210046ce4e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=kiva_smote.shape[1:], activation='relu'))\n",
    "model.add(Dense(1000,  activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "  \n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.0015), metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.bestsmote.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_res, smote_train_y,validation_split = 0.2,epochs = 80, batch_size= 1000,callbacks=[checkpointer],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "747891/747891 [==============================] - 107s 143us/step - loss: 0.3482 - acc: 0.8627\n",
      "67117/67117 [==============================] - 8s 114us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=kiva_smote.shape[1:], activation='relu'))\n",
    "model.add(Dense(1000,  activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.load_weights(\"weights.bestsmote.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.0015), metrics=['accuracy'])\n",
    "model.fit(X_res,smote_train_y,batch_size= 1000)\n",
    "score = model.evaluate(X_test,keras_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     full funded       0.99      0.94      0.96     62278\n",
      "      non funded       0.71      0.93      0.81       319\n",
      "partially funded       0.49      0.83      0.62      4520\n",
      "\n",
      "     avg / total       0.95      0.93      0.94     67117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "keras_test_y = np.argmax(keras_test_y, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(keras_test_y, y_pred, target_names=['full funded', 'non funded','partially funded']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Undersampling</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind data reduction is to resize the biggest class, thus giving the smaller classes a higher weight. The reduction is done by removing randomly rows buy for example using pandas sample method. The problem with data reduction is that we risk losing information. \n",
    "\n",
    "In this case the problem is accentuated by the small size of the non funded loans. In order to balance information loss and weight compensation i will reduce the biggest class to 20 percent of the original size even if that means that the smallest class still will be proportionally smaller. If the reduction still shows some imbalances I will further reduce the proportion of the biggest class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiva_undersampling = pd.read_csv('data_files/kiva_keras.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79462, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totally_funded = kiva_undersampling.loc[kiva_undersampling.loan_status == 'Totally funded']\n",
    "partially_funded = kiva_undersampling.loc[kiva_undersampling.loan_status == 'partially funded']\n",
    "not_funded = kiva_undersampling.loc[kiva_undersampling.loan_status == 'not funded']\n",
    "\n",
    "\n",
    "df1 = totally_funded.sample(frac=.05)\n",
    "df2 = partially_funded\n",
    "df3 = not_funded\n",
    "kiva_reduced = (pd.concat([df1,df2,df3]))\n",
    "kiva_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to .sample(frac=.05). Reducing the biggest class to 20 % did not produce significant results so I reduced gradually to 5 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preproccesing keras\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "#features_to_scale = ['loan_amount','term_in_months','lender_count']\n",
    "scaler = MinMaxScaler()\n",
    "#scaled_features = scaler.fit_transform(kiva[features_to_scale])\n",
    "\n",
    "kiva_reduced = pd.get_dummies(data=kiva_reduced, columns=['activity','description', 'sector', 'country','currency','repayment_interval','borrower_genders'])\n",
    "kiva_reduced[['loan_amount','term_in_months','lender_count']] = scaler.fit_transform(kiva_reduced[['loan_amount','term_in_months','lender_count']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = kiva_reduced.loan_status\n",
    "kiva_reduced.drop(['loan_status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_red, X_test, y_train_red, y_test = train_test_split(kiva_reduced, y, test_size=0.2, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Encode train_y\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_step_one = le.fit_transform(y_train_red)\n",
    "reduced_train_y = to_categorical(y_train_step_one)\n",
    "# Encode train_y\n",
    "\n",
    "y_test_step_one = le.fit_transform(y_test)\n",
    "keras_test_y = to_categorical(y_test_step_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50855 samples, validate on 12714 samples\n",
      "Epoch 1/80\n",
      "50855/50855 [==============================] - 11s 212us/step - loss: 0.7624 - acc: 0.6376 - val_loss: 0.6828 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68284, saving model to weights.bestredu.hdf5\n",
      "Epoch 2/80\n",
      "50855/50855 [==============================] - 9s 174us/step - loss: 0.6567 - acc: 0.7148 - val_loss: 0.6589 - val_acc: 0.7141\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68284 to 0.65886, saving model to weights.bestredu.hdf5\n",
      "Epoch 3/80\n",
      "50855/50855 [==============================] - 9s 172us/step - loss: 0.6349 - acc: 0.7259 - val_loss: 0.6417 - val_acc: 0.7227\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65886 to 0.64171, saving model to weights.bestredu.hdf5\n",
      "Epoch 4/80\n",
      "50855/50855 [==============================] - 8s 158us/step - loss: 0.6209 - acc: 0.7343 - val_loss: 0.6314 - val_acc: 0.7306\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64171 to 0.63139, saving model to weights.bestredu.hdf5\n",
      "Epoch 5/80\n",
      "50855/50855 [==============================] - 10s 187us/step - loss: 0.6085 - acc: 0.7405 - val_loss: 0.6187 - val_acc: 0.7336\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.63139 to 0.61872, saving model to weights.bestredu.hdf5\n",
      "Epoch 6/80\n",
      "50855/50855 [==============================] - 9s 179us/step - loss: 0.5981 - acc: 0.7422 - val_loss: 0.6125 - val_acc: 0.7365\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.61872 to 0.61247, saving model to weights.bestredu.hdf5\n",
      "Epoch 7/80\n",
      "50855/50855 [==============================] - 11s 218us/step - loss: 0.5864 - acc: 0.7484 - val_loss: 0.6188 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.61247\n",
      "Epoch 8/80\n",
      "50855/50855 [==============================] - 8s 165us/step - loss: 0.5764 - acc: 0.7530 - val_loss: 0.5958 - val_acc: 0.7485\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.61247 to 0.59578, saving model to weights.bestredu.hdf5\n",
      "Epoch 9/80\n",
      "50855/50855 [==============================] - 8s 167us/step - loss: 0.5680 - acc: 0.7587 - val_loss: 0.5786 - val_acc: 0.7538\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.59578 to 0.57864, saving model to weights.bestredu.hdf5\n",
      "Epoch 10/80\n",
      "50855/50855 [==============================] - 8s 164us/step - loss: 0.5603 - acc: 0.7626 - val_loss: 0.5902 - val_acc: 0.7511\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.57864\n",
      "Epoch 11/80\n",
      "50855/50855 [==============================] - 10s 201us/step - loss: 0.5521 - acc: 0.7664 - val_loss: 0.5834 - val_acc: 0.7552\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.57864\n",
      "Epoch 12/80\n",
      "50855/50855 [==============================] - 9s 169us/step - loss: 0.5451 - acc: 0.7696 - val_loss: 0.5675 - val_acc: 0.7562\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.57864 to 0.56753, saving model to weights.bestredu.hdf5\n",
      "Epoch 13/80\n",
      "50855/50855 [==============================] - 9s 170us/step - loss: 0.5376 - acc: 0.7722 - val_loss: 0.5604 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.56753 to 0.56044, saving model to weights.bestredu.hdf5\n",
      "Epoch 14/80\n",
      "50855/50855 [==============================] - 11s 224us/step - loss: 0.5300 - acc: 0.7787 - val_loss: 0.5714 - val_acc: 0.7592\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.56044\n",
      "Epoch 15/80\n",
      "50855/50855 [==============================] - 9s 177us/step - loss: 0.5270 - acc: 0.7798 - val_loss: 0.5395 - val_acc: 0.7698\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.56044 to 0.53950, saving model to weights.bestredu.hdf5\n",
      "Epoch 16/80\n",
      "50855/50855 [==============================] - 8s 166us/step - loss: 0.5199 - acc: 0.7799 - val_loss: 0.5535 - val_acc: 0.7658\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.53950\n",
      "Epoch 17/80\n",
      "50855/50855 [==============================] - 9s 183us/step - loss: 0.5145 - acc: 0.7830 - val_loss: 0.5324 - val_acc: 0.7748\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.53950 to 0.53240, saving model to weights.bestredu.hdf5\n",
      "Epoch 18/80\n",
      "50855/50855 [==============================] - 11s 209us/step - loss: 0.5111 - acc: 0.7838 - val_loss: 0.5416 - val_acc: 0.7714\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.53240\n",
      "Epoch 19/80\n",
      "50855/50855 [==============================] - 9s 168us/step - loss: 0.5048 - acc: 0.7871 - val_loss: 0.5243 - val_acc: 0.7794\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.53240 to 0.52426, saving model to weights.bestredu.hdf5\n",
      "Epoch 20/80\n",
      "50855/50855 [==============================] - 10s 189us/step - loss: 0.5009 - acc: 0.7894 - val_loss: 0.5200 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.52426 to 0.51997, saving model to weights.bestredu.hdf5\n",
      "Epoch 21/80\n",
      "50855/50855 [==============================] - 9s 170us/step - loss: 0.4971 - acc: 0.7905 - val_loss: 0.5735 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.51997\n",
      "Epoch 22/80\n",
      "50855/50855 [==============================] - 8s 165us/step - loss: 0.4938 - acc: 0.7909 - val_loss: 0.5385 - val_acc: 0.7771\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.51997\n",
      "Epoch 23/80\n",
      "50855/50855 [==============================] - 9s 182us/step - loss: 0.4845 - acc: 0.7962 - val_loss: 0.4949 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.51997 to 0.49493, saving model to weights.bestredu.hdf5\n",
      "Epoch 24/80\n",
      "50855/50855 [==============================] - 11s 210us/step - loss: 0.4818 - acc: 0.7969 - val_loss: 0.5046 - val_acc: 0.7884\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.49493\n",
      "Epoch 25/80\n",
      "50855/50855 [==============================] - 12s 228us/step - loss: 0.4762 - acc: 0.7996 - val_loss: 0.4863 - val_acc: 0.7955\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.49493 to 0.48631, saving model to weights.bestredu.hdf5\n",
      "Epoch 26/80\n",
      "50855/50855 [==============================] - 12s 237us/step - loss: 0.4749 - acc: 0.7986 - val_loss: 0.4806 - val_acc: 0.8033\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.48631 to 0.48063, saving model to weights.bestredu.hdf5\n",
      "Epoch 27/80\n",
      "50855/50855 [==============================] - 10s 202us/step - loss: 0.4696 - acc: 0.8007 - val_loss: 0.5066 - val_acc: 0.7843\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.48063\n",
      "Epoch 28/80\n",
      "50855/50855 [==============================] - 9s 177us/step - loss: 0.4656 - acc: 0.8011 - val_loss: 0.4769 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.48063 to 0.47695, saving model to weights.bestredu.hdf5\n",
      "Epoch 29/80\n",
      "50855/50855 [==============================] - 9s 173us/step - loss: 0.4595 - acc: 0.8034 - val_loss: 0.4649 - val_acc: 0.8036\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.47695 to 0.46488, saving model to weights.bestredu.hdf5\n",
      "Epoch 30/80\n",
      "50855/50855 [==============================] - 9s 177us/step - loss: 0.4544 - acc: 0.8046 - val_loss: 0.4983 - val_acc: 0.7878\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.46488\n",
      "Epoch 31/80\n",
      "50855/50855 [==============================] - 9s 174us/step - loss: 0.4524 - acc: 0.8052 - val_loss: 0.4711 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.46488\n",
      "Epoch 32/80\n",
      "50855/50855 [==============================] - 9s 176us/step - loss: 0.4481 - acc: 0.8062 - val_loss: 0.4700 - val_acc: 0.8012\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.46488\n",
      "Epoch 33/80\n",
      "50855/50855 [==============================] - 9s 182us/step - loss: 0.4423 - acc: 0.8069 - val_loss: 0.5062 - val_acc: 0.7741\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.46488\n",
      "Epoch 34/80\n",
      "50855/50855 [==============================] - 9s 174us/step - loss: 0.4391 - acc: 0.8085 - val_loss: 0.4442 - val_acc: 0.8064\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.46488 to 0.44419, saving model to weights.bestredu.hdf5\n",
      "Epoch 35/80\n",
      "50855/50855 [==============================] - 9s 175us/step - loss: 0.4345 - acc: 0.8111 - val_loss: 0.4351 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.44419 to 0.43514, saving model to weights.bestredu.hdf5\n",
      "Epoch 36/80\n",
      "50855/50855 [==============================] - 9s 174us/step - loss: 0.4332 - acc: 0.8096 - val_loss: 0.4524 - val_acc: 0.8049\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.43514\n",
      "Epoch 37/80\n",
      "50855/50855 [==============================] - 9s 177us/step - loss: 0.4279 - acc: 0.8138 - val_loss: 0.4477 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.43514\n",
      "Epoch 38/80\n",
      "50855/50855 [==============================] - 9s 171us/step - loss: 0.4270 - acc: 0.8141 - val_loss: 0.4299 - val_acc: 0.8132\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.43514 to 0.42989, saving model to weights.bestredu.hdf5\n",
      "Epoch 39/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50855/50855 [==============================] - 9s 176us/step - loss: 0.4206 - acc: 0.8158 - val_loss: 0.4292 - val_acc: 0.8150\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.42989 to 0.42920, saving model to weights.bestredu.hdf5\n",
      "Epoch 40/80\n",
      "50855/50855 [==============================] - 8s 164us/step - loss: 0.4230 - acc: 0.8149 - val_loss: 0.4370 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.42920\n",
      "Epoch 41/80\n",
      "50855/50855 [==============================] - 8s 162us/step - loss: 0.4169 - acc: 0.8179 - val_loss: 0.4339 - val_acc: 0.8114\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.42920\n",
      "Epoch 42/80\n",
      "50855/50855 [==============================] - 9s 168us/step - loss: 0.4129 - acc: 0.8205 - val_loss: 0.4359 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.42920\n",
      "Epoch 43/80\n",
      "50855/50855 [==============================] - 9s 168us/step - loss: 0.4098 - acc: 0.8197 - val_loss: 0.4499 - val_acc: 0.8046\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.42920\n",
      "Epoch 44/80\n",
      "50855/50855 [==============================] - 9s 175us/step - loss: 0.4103 - acc: 0.8193 - val_loss: 0.4188 - val_acc: 0.8225\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.42920 to 0.41883, saving model to weights.bestredu.hdf5\n",
      "Epoch 45/80\n",
      "50855/50855 [==============================] - 8s 162us/step - loss: 0.4060 - acc: 0.8214 - val_loss: 0.4093 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.41883 to 0.40934, saving model to weights.bestredu.hdf5\n",
      "Epoch 46/80\n",
      "50855/50855 [==============================] - 9s 182us/step - loss: 0.4038 - acc: 0.8231 - val_loss: 0.4494 - val_acc: 0.8102\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.40934\n",
      "Epoch 47/80\n",
      "50855/50855 [==============================] - 9s 169us/step - loss: 0.4009 - acc: 0.8240 - val_loss: 0.4458 - val_acc: 0.8121\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.40934\n",
      "Epoch 48/80\n",
      "50855/50855 [==============================] - 9s 183us/step - loss: 0.3979 - acc: 0.8276 - val_loss: 0.4079 - val_acc: 0.8188\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.40934 to 0.40789, saving model to weights.bestredu.hdf5\n",
      "Epoch 49/80\n",
      "50855/50855 [==============================] - 9s 168us/step - loss: 0.3985 - acc: 0.8245 - val_loss: 0.4315 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.40789\n",
      "Epoch 50/80\n",
      "50855/50855 [==============================] - 9s 175us/step - loss: 0.3940 - acc: 0.8270 - val_loss: 0.3947 - val_acc: 0.8321\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.40789 to 0.39472, saving model to weights.bestredu.hdf5\n",
      "Epoch 51/80\n",
      "50855/50855 [==============================] - 12s 227us/step - loss: 0.3884 - acc: 0.8315 - val_loss: 0.4651 - val_acc: 0.7868\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.39472\n",
      "Epoch 52/80\n",
      "50855/50855 [==============================] - 9s 176us/step - loss: 0.3956 - acc: 0.8249 - val_loss: 0.4413 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.39472\n",
      "Epoch 53/80\n",
      "50855/50855 [==============================] - 10s 194us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.4975 - val_acc: 0.7859\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.39472\n",
      "Epoch 54/80\n",
      "50855/50855 [==============================] - 9s 171us/step - loss: 0.3889 - acc: 0.8292 - val_loss: 0.3984 - val_acc: 0.8245\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.39472\n",
      "Epoch 55/80\n",
      "50855/50855 [==============================] - 9s 168us/step - loss: 0.3852 - acc: 0.8298 - val_loss: 0.3987 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.39472\n",
      "Epoch 56/80\n",
      "50855/50855 [==============================] - 9s 169us/step - loss: 0.3804 - acc: 0.8338 - val_loss: 0.4077 - val_acc: 0.8196\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.39472\n",
      "Epoch 57/80\n",
      "50855/50855 [==============================] - 9s 169us/step - loss: 0.3809 - acc: 0.8324 - val_loss: 0.3805 - val_acc: 0.8377\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.39472 to 0.38054, saving model to weights.bestredu.hdf5\n",
      "Epoch 58/80\n",
      "50855/50855 [==============================] - 9s 172us/step - loss: 0.3776 - acc: 0.8357 - val_loss: 0.3906 - val_acc: 0.8279\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38054\n",
      "Epoch 59/80\n",
      "50855/50855 [==============================] - 9s 182us/step - loss: 0.3761 - acc: 0.8341 - val_loss: 0.4059 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38054\n",
      "Epoch 60/80\n",
      "50855/50855 [==============================] - 9s 171us/step - loss: 0.3772 - acc: 0.8317 - val_loss: 0.3987 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38054\n",
      "Epoch 61/80\n",
      "50855/50855 [==============================] - 9s 169us/step - loss: 0.3779 - acc: 0.8313 - val_loss: 0.4025 - val_acc: 0.8239\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38054\n",
      "Epoch 62/80\n",
      "50855/50855 [==============================] - 9s 169us/step - loss: 0.3748 - acc: 0.8357 - val_loss: 0.3852 - val_acc: 0.8370\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38054\n",
      "Epoch 63/80\n",
      "50855/50855 [==============================] - 9s 171us/step - loss: 0.3719 - acc: 0.8380 - val_loss: 0.3713 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.38054 to 0.37128, saving model to weights.bestredu.hdf5\n",
      "Epoch 64/80\n",
      "50855/50855 [==============================] - 9s 172us/step - loss: 0.3685 - acc: 0.8394 - val_loss: 0.4860 - val_acc: 0.7859\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.37128\n",
      "Epoch 65/80\n",
      "50855/50855 [==============================] - 9s 170us/step - loss: 0.3690 - acc: 0.8383 - val_loss: 0.4011 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.37128\n",
      "Epoch 66/80\n",
      "50855/50855 [==============================] - 9s 186us/step - loss: 0.3656 - acc: 0.8378 - val_loss: 0.4225 - val_acc: 0.8082\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.37128\n",
      "Epoch 67/80\n",
      "50855/50855 [==============================] - 9s 168us/step - loss: 0.3675 - acc: 0.8386 - val_loss: 0.3646 - val_acc: 0.8450\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.37128 to 0.36461, saving model to weights.bestredu.hdf5\n",
      "Epoch 68/80\n",
      "50855/50855 [==============================] - 9s 181us/step - loss: 0.3609 - acc: 0.8403 - val_loss: 0.3748 - val_acc: 0.8357\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.36461\n",
      "Epoch 69/80\n",
      "50855/50855 [==============================] - 9s 177us/step - loss: 0.3651 - acc: 0.8384 - val_loss: 0.3927 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.36461\n",
      "Epoch 70/80\n",
      "50855/50855 [==============================] - 9s 175us/step - loss: 0.3567 - acc: 0.8435 - val_loss: 0.4088 - val_acc: 0.8187\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.36461\n",
      "Epoch 71/80\n",
      "50855/50855 [==============================] - 9s 172us/step - loss: 0.3637 - acc: 0.8407 - val_loss: 0.3879 - val_acc: 0.8346\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.36461\n",
      "Epoch 72/80\n",
      "50855/50855 [==============================] - 9s 173us/step - loss: 0.3618 - acc: 0.8395 - val_loss: 0.4033 - val_acc: 0.8252\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.36461\n",
      "Epoch 73/80\n",
      "50855/50855 [==============================] - 9s 185us/step - loss: 0.3523 - acc: 0.8462 - val_loss: 0.3565 - val_acc: 0.8521\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.36461 to 0.35650, saving model to weights.bestredu.hdf5\n",
      "Epoch 74/80\n",
      "50855/50855 [==============================] - 9s 173us/step - loss: 0.3548 - acc: 0.8446 - val_loss: 0.3682 - val_acc: 0.8458\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.35650\n",
      "Epoch 75/80\n",
      "50855/50855 [==============================] - 9s 174us/step - loss: 0.3554 - acc: 0.8445 - val_loss: 0.3903 - val_acc: 0.8336\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.35650\n",
      "Epoch 76/80\n",
      "50855/50855 [==============================] - 9s 169us/step - loss: 0.3479 - acc: 0.8473 - val_loss: 0.4313 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.35650\n",
      "Epoch 77/80\n",
      "50855/50855 [==============================] - 9s 171us/step - loss: 0.3517 - acc: 0.8446 - val_loss: 0.4015 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.35650\n",
      "Epoch 78/80\n",
      "50855/50855 [==============================] - 9s 171us/step - loss: 0.3518 - acc: 0.8438 - val_loss: 0.3774 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.35650\n",
      "Epoch 79/80\n",
      "50855/50855 [==============================] - 9s 178us/step - loss: 0.3449 - acc: 0.8509 - val_loss: 0.3957 - val_acc: 0.8331\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.35650\n",
      "Epoch 80/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50855/50855 [==============================] - 9s 172us/step - loss: 0.3458 - acc: 0.8485 - val_loss: 0.3881 - val_acc: 0.8345\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.35650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x210058674a8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=kiva_reduced.shape[1:], activation='relu'))\n",
    "model.add(Dense(1000,  activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "  \n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.0015), metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.bestredu.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train_red,reduced_train_y,validation_split = 0.2,epochs = 80,batch_size= 1000,callbacks=[checkpointer],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     full funded       0.85      0.83      0.84      6063\n",
      "      non funded       0.70      0.72      0.71       721\n",
      "partially funded       0.87      0.89      0.88      9109\n",
      "\n",
      "     avg / total       0.86      0.86      0.85     15893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "model.load_weights(\"weights.bestredu.hdf5\")\n",
    "keras_test_y = np.argmax(keras_test_y, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(keras_test_y, y_pred, target_names=['full funded', 'non funded','partially funded']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Resampling the datasets conclusion</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "I tried two resampling approaches to improve the results from part two / Keras. Both improved the results for the two smallest classes. \n",
    "\n",
    "\n",
    "Augmenting the dataset with SMOTE helped to improve f1 score for the partially funded loans, but at the cost of a worse result for the non funded loans and for the fully funded loans.\n",
    "Undersampling gave better results for the non and partially funded loans but at detriment of the fully funded loans. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Final Conclusion</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project was to predict if a loan from Kiva gets funded, especially for those outcomes that could have negative consequences for the borrower. Based on the assumption that there is not a single model that serves/fits all purposes I compared Sklearn algorithms with a Keras neural network with and without resampling to overcome class imbalance<br>\n",
    "\n",
    "As we can see from the following table the different algorithms showed some differences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm | f1 fully funded   | f1 non funded   | f1 partially funded |\n",
    "|------|------|------|------|\n",
    "|   Random forest| 0.98 | 1.00| 0.71  |\n",
    "|   Keras| 0.98 | 0.53| 0.67  |\n",
    "|   Keras SMOTE| 0.96 | 0.81 | 0.62  |\n",
    "|   Keras undersampling| 0.84 | 0.71 | 0.88  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first good candidate was already found in the first part, where the Random forest algorithm achieved perfect score, with no misclassification for one of the the tree classes, the non funded loans. These was the most critical outcome, as a non funded loan means the death of the borrowers project.\n",
    "Randomforest had problems predicting the correct outcome for the partially funded loans. \n",
    "\n",
    "The keras based model improved a little bit the performance for the partially funded loans but failed with respect of the of the smallest class, the non funded loans. It’s interesting, to point out that the Sklearn MLP showed similar behaviour.\n",
    "\n",
    "Resampling by augmenting (SMOTE) improved the results for the the non funded loans but showed worse results for the rest of the classes. Undersampling improved the result of the non funded and partially funded loans but didn't perform well for the biggest class.\n",
    "\n",
    "The overall conclusion is that Randomforest is suited for the problem/domain as it achieved the best possible predictions for the most critical class for the borrowers, the non fundet loans. Using f1 as metric it outperformed Keras and did much more faster. \n",
    "\n",
    "\n",
    "Results for Keras could improve by increasing the search space for the Gridsearch/Randomsearch for Keras and by extending the search space to include also the architecture (layers and hidden nodes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
